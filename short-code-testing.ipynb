{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "value:  0\n",
      "idx:  1\n",
      "value:  2\n",
      "idx:  2\n",
      "value:  6\n"
     ]
    }
   ],
   "source": [
    "def createGenerator():\n",
    "    for i in range(3):\n",
    "        yield (i*i + i)\n",
    "    \n",
    "for idx, i in enumerate(createGenerator()):\n",
    "    print(\"idx: \", idx)\n",
    "    print(\"value: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [ 0 10 20 30 40 50 60 70 80 90]\n",
      "idx:  [9 8 5 7 1 0 6 3 4 2]\n",
      "B:  [90 80 50 70 10  0 60 30 40 20]\n",
      "idx_sort:  [0 1 2 3 4 5 6 7 8 9]\n",
      "C:  [ 0 10 20 30 40 50 60 70 80 90]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "idx = np.random.permutation(10)\n",
    "idx_sort = np.arange(10)\n",
    "B = A[idx]\n",
    "C = A[idx_sort]\n",
    "\n",
    "print (\"A: \", A)\n",
    "print(\"idx: \", idx)\n",
    "print(\"B: \", B)\n",
    "print(\"idx_sort: \", idx_sort)\n",
    "print(\"C: \", C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "New line\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "X_2D = None\n",
    "h = np.array([[1,2],[3,4],[5,6],[7,8],[9,10]])\n",
    "print(h)\n",
    "\n",
    "for i in range(5):\n",
    "    if i == 0:\n",
    "        X_2D = h[i]\n",
    "    else:\n",
    "        X_2D  = np.hstack((X_2D, h[i]))\n",
    "\n",
    "print(\"New line\")\n",
    "print (X_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[2.5 7.5]\n",
      "[1.25 1.25]\n",
      "first vec\n",
      "[[1 6]\n",
      " [2 7]\n",
      " [3 8]\n",
      " [4 9]]\n",
      "vec after mean\n",
      "[[-1.5 -1.5]\n",
      " [-0.5 -0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 1.5  1.5]]\n",
      "vec after var\n",
      "[[-1.2 -1.2]\n",
      " [-0.4 -0.4]\n",
      " [ 0.4  0.4]\n",
      " [ 1.2  1.2]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "y = np.array([6,7,8,9])\n",
    "vec = np.transpose(np.vstack((x, y)))\n",
    "print(vec.shape)\n",
    "mean = np.mean(vec, axis=0)\n",
    "var = np.var (vec, axis=0)\n",
    "print(mean)\n",
    "print(var)\n",
    "print(\"first vec\")\n",
    "print(vec)\n",
    "vec = (vec - mean)\n",
    "print(\"vec after mean\")\n",
    "print(vec)\n",
    "vec = vec/ var\n",
    "print(\"vec after var\")\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =  tensor([[0.2000, 0.8000],\n",
      "        [0.7000, 0.3000]], dtype=torch.float64)\n",
      "A_ent =  tensor([[-0.3219, -0.1785],\n",
      "        [-0.2497, -0.3612]], dtype=torch.float64)\n",
      "ent =  tensor(1.1113, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#A = torch.tensor(np.array([[3.43, -2.9],[3.435, -2.902]]))\n",
    "\n",
    "A = torch.tensor(np.array([[0.2, 0.8],[0.7, 0.3]]))\n",
    "#A_ent = F.softmax(A, dim = 1) *  F.log_softmax(A, dim=1)\n",
    "\n",
    "A_ent = A * torch.log(A)\n",
    "ent = -1*A_ent.sum()\n",
    "print(\"A = \", A)\n",
    "print(\"A_ent = \", A_ent)\n",
    "print(\"ent = \", ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3611918412977808\n"
     ]
    }
   ],
   "source": [
    "print(0.3*np.log(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_max_sum(list_sublists):\n",
    "    max_sum = sum(list_sublists[0])\n",
    "    sublist_max_sum = list_sublists[0]\n",
    "    for i in range(len(list_sublists)):\n",
    "        if sum(list_sublists[i]) > max_sum:\n",
    "            max_sum = sum(list_sublists[i])\n",
    "            sublist_max_sum = list_sublists[i]\n",
    "    \n",
    "    return sublist_max_sum\n",
    "\n",
    "list_sublists = [[1,2,3],[1,5,9],[3,4,1]]\n",
    "sublist_max_sum = get_list_max_sum(list_sublists)\n",
    "print(sublist_max_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = np.log(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.53999298e-05 2.20264658e+04]\n",
      "2.0611536181902033e-09\n",
      "0.9999999979388463\n"
     ]
    }
   ],
   "source": [
    "# pot = np.array([-10, -3,-2,-1,1,2,3])\n",
    "pot = np.array([-10, 10])\n",
    "softmax = np.exp(pot)\n",
    "print(softmax)\n",
    "print(softmax[0]/np.sum(softmax))\n",
    "print(softmax[1]/np.sum(softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "[[ 1.  1.]\n",
      " [ 2.  2.]\n",
      " [ 3.  3.]\n",
      " [ 4.  4.]\n",
      " [ 5.  5.]\n",
      " [ 6.  6.]\n",
      " [ 7.  7.]\n",
      " [ 8.  8.]\n",
      " [ 9.  9.]\n",
      " [10. 10.]]\n",
      "[5.5 5.5]\n",
      "cluster centers:\n",
      "[[2. 2.]\n",
      " [7. 7.]]\n",
      "dist:\n",
      "[[ 2. 12.]\n",
      " [ 0. 10.]\n",
      " [ 2.  8.]\n",
      " [ 4.  6.]\n",
      " [ 6.  4.]\n",
      " [ 8.  2.]\n",
      " [10.  0.]\n",
      " [12.  2.]\n",
      " [14.  4.]\n",
      " [16.  6.]]\n",
      "labels:\n",
      "[0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1,11).reshape(-1,1).astype(float)\n",
    "y = np.arange(1,11).reshape(-1,1).astype(float)\n",
    "X = np.hstack((x,y))\n",
    "n_clusters = 2\n",
    "print (X.shape)\n",
    "\n",
    "print(X)\n",
    "print(np.median(X, axis=0))\n",
    "\n",
    "idx_init = np.random.permutation(X.shape[0])[:n_clusters]\n",
    "cluster_centers = X[idx_init,:]\n",
    "dist = manhattan_distances(X, cluster_centers)\n",
    "labels = dist.argmin(axis=1)\n",
    "print(\"cluster centers:\")\n",
    "print(cluster_centers)\n",
    "print(\"dist:\")\n",
    "print(dist)\n",
    "print(\"labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1]\n",
      " [ 2  2]\n",
      " [ 3  3]\n",
      " [ 4  4]\n",
      " [ 5  5]\n",
      " [ 6  6]\n",
      " [ 7  7]\n",
      " [ 8  8]\n",
      " [ 9  9]\n",
      " [10 10]]\n",
      "[[ 3  3]\n",
      " [ 4  4]\n",
      " [ 5  5]\n",
      " [ 6  6]\n",
      " [ 7  7]\n",
      " [ 8  8]\n",
      " [ 9  9]\n",
      " [10 10]\n",
      " [11 11]\n",
      " [12 12]]\n",
      "\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "Y = X + 2\n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"\")\n",
    "mse = mean_squared_error(X, Y)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_medians_manhattan(X, n_clusters, cluster_centers_init = None, max_iter = 1000, tol = 1e-4, verbose = False):\n",
    "    \"\"\"\n",
    "    Inspired to some degree by the implementation found in: https://gist.github.com/mblondel/1451300.\n",
    "    Implements the algorithm k-medians by using the manhattan distance.\n",
    "    Arguments:\n",
    "        X: data (size: (n, d), n = number of points, d = dimension of the poitns) \n",
    "            to apply the k-medians algorithm.\n",
    "        n_clusters: number of (supposed) clusters.\n",
    "        cluster_centers_init: initial guess of the centers of the clusters if any.\n",
    "        max_iter: maximum number of iterations of the algorithm.\n",
    "        tol: tolerance of minimum variation between the previous and current iteration.\n",
    "        verbose: boolean variable to use verbose mode.\n",
    "        \n",
    "    Outputs:\n",
    "        cluster_centers: cluster centers found by the algorithm.\n",
    "        labels: labels assigned according to the minimum manhattan distance\n",
    "            to the cluster centers.\n",
    "    \"\"\"\n",
    "    if cluster_centers_init is not None:\n",
    "        cluster_centers = cluster_centers_init\n",
    "    else:\n",
    "        idx_init = np.random.permutation(X.shape[0])[:n_clusters]\n",
    "        cluster_centers = X[idx_init,:]\n",
    "    \n",
    "    for i in range (max_iter):\n",
    "        dist = manhattan_distances(X, cluster_centers)\n",
    "        labels = dist.argmin(axis=1)\n",
    "        cluster_centers_old = cluster_centers.copy()\n",
    "        if verbose:\n",
    "            print(\"iter = {}\".format(i))\n",
    "            print(\"cluster_centers =\\n{}\".format(cluster_centers))\n",
    "            print(\"labels = {}\\n\".format(labels));\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(labels == j)\n",
    "            cluster_centers[j] = np.median(X[idx], axis=0)\n",
    "        \n",
    "        if mean_squared_error(cluster_centers, cluster_centers_old) < tol:\n",
    "            break\n",
    "    \n",
    "    return cluster_centers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3.]\n",
      " [8. 8.]]\n",
      "[0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "cluster_centers_init = np.array ([[2.0,2.0],[7.0,7.0]])\n",
    "cluster_centers, labels = k_medians_manhattan(X, n_clusters = 2, cluster_centers_init = cluster_centers_init)\n",
    "print(cluster_centers)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000],\n",
      "        [1.5000, 1.5000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "h = torch.tensor(np.array([[2.0, 2.0],[3.0, 3.0]]))\n",
    "b = F.softmax(h, dim = 1) * h\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c = a + [b[0], b[1]]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "l = [1,2]\n",
    "a = tuple(l)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.10.2020-16:16:05\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime(\"%d.%m.%Y-%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
